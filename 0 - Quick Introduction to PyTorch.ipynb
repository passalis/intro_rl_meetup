{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Introduction to PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, lets load a dataset. This is extremely easy with the loaders provided by PyTorch (we will not focus on these, since they are not usually used in Deep RL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_set = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True, num_workers=1)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=True, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a network is quite straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
    "        self.fc1 = nn.Linear(64 * 5 * 5, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, 64 * 5 * 5)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "\n",
    "# Move the network to the GPU\n",
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nn.Module takes cares of most of the logistics (e.g., keeping track of the parameters of the network, etc.). We should also define the metric according to which the network will be optimized, as well the optimizer that will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the nn.CrossEntropyLoss() combines the Softmax activation and the cross-entropy loss into one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to train the network. Note that we have to write the actual training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 - total loss: 377.8469\n",
      "epoch 2 - total loss: 84.9901\n",
      "epoch 3 - total loss: 65.3377\n",
      "epoch 4 - total loss: 56.0823\n",
      "epoch 5 - total loss: 49.8744\n",
      "epoch 6 - total loss: 45.1537\n",
      "epoch 7 - total loss: 41.2219\n",
      "epoch 8 - total loss: 37.7816\n",
      "epoch 9 - total loss: 35.7738\n",
      "epoch 10 - total loss: 32.0974\n",
      "epoch 11 - total loss: 31.8087\n",
      "epoch 12 - total loss: 28.8356\n",
      "epoch 13 - total loss: 29.6300\n",
      "epoch 14 - total loss: 27.2517\n",
      "epoch 15 - total loss: 24.8246\n",
      "epoch 16 - total loss: 25.2840\n",
      "epoch 17 - total loss: 24.6760\n",
      "epoch 18 - total loss: 22.6854\n",
      "epoch 19 - total loss: 23.1305\n",
      "epoch 20 - total loss: 19.9809\n"
     ]
    }
   ],
   "source": [
    "def train_network(net, loader, criterion, optimizer, iters=30):\n",
    "    for epoch in range(iters): \n",
    "\n",
    "        current_loss = 0.0\n",
    "        for data in loader:\n",
    "\n",
    "            inputs, labels = data\n",
    "\n",
    "            #Move the data to the GPU\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Get the network output\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            # Calculate the loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Back-propagate the loss\n",
    "            loss.backward()\n",
    "\n",
    "            # Run the optimizer for one step\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            current_loss += loss.item()\n",
    "        print (\"epoch %d - total loss: %5.4f\"%(epoch+1, current_loss))\n",
    "\n",
    "train_network(net, train_loader, criterion, optimizer, iters=20 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function for evaluating the network and measuring the accuracy using a data loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_net(net, loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100.0 * correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the network and measure the train and test errors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error =  0.7833333333333314\n",
      "Test error =  1.2199999999999989\n"
     ]
    }
   ],
   "source": [
    "print(\"Train error = \", 100 - evaluate_net(net, train_loader))\n",
    "print(\"Test error = \", 100 - evaluate_net(net, test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Does the order of the samples matter? Can we train the network with batches of correlated samples?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sort the data according to their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# A dirty-hack to sort the samples\n",
    "idx = np.argsort(train_set.train_labels)\n",
    "train_set.train_labels = train_set.train_labels[idx]\n",
    "train_set.train_data = train_set.train_data[idx]\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=False, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train a network again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 - total loss: 2093.9526\n",
      "epoch 2 - total loss: 2159.8300\n",
      "epoch 3 - total loss: 2159.8273\n",
      "epoch 4 - total loss: 2159.8246\n",
      "epoch 5 - total loss: 2148.9803\n",
      "epoch 6 - total loss: 2160.8550\n",
      "epoch 7 - total loss: 2159.9004\n",
      "epoch 8 - total loss: 2159.8268\n",
      "epoch 9 - total loss: 2160.4560\n",
      "epoch 10 - total loss: 2159.8247\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "net = net.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "train_network(net, train_loader, criterion, optimizer, iters=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error =  90.13666666666667\n",
      "Test error =  90.2\n"
     ]
    }
   ],
   "source": [
    "print(\"Train error = \", 100 - evaluate_net(net, train_loader))\n",
    "print(\"Test error = \", 100 - evaluate_net(net, test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying with a smaller learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 - total loss: 1748.0338\n",
      "epoch 2 - total loss: 1417.3277\n",
      "epoch 3 - total loss: 783.4411\n",
      "epoch 4 - total loss: 289.9167\n",
      "epoch 5 - total loss: 164.8857\n",
      "epoch 6 - total loss: 124.0721\n",
      "epoch 7 - total loss: 103.8610\n",
      "epoch 8 - total loss: 92.8206\n",
      "epoch 9 - total loss: 89.1798\n",
      "epoch 10 - total loss: 83.6032\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "net = net.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
    "\n",
    "train_network(net, train_loader, criterion, optimizer, iters=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error =  64.20333333333333\n",
      "Test error =  63.78\n"
     ]
    }
   ],
   "source": [
    "print(\"Train error = \", 100 - evaluate_net(net, train_loader))\n",
    "print(\"Test error = \", 100 - evaluate_net(net, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 - total loss: 75.5576\n",
      "epoch 2 - total loss: 66.1821\n",
      "epoch 3 - total loss: 61.7868\n",
      "epoch 4 - total loss: 59.1433\n",
      "epoch 5 - total loss: 58.0251\n",
      "epoch 6 - total loss: 52.7888\n",
      "epoch 7 - total loss: 53.0982\n",
      "epoch 8 - total loss: 52.6813\n",
      "epoch 9 - total loss: 51.5730\n",
      "epoch 10 - total loss: 52.2762\n",
      "epoch 11 - total loss: 56.4309\n",
      "epoch 12 - total loss: 51.6152\n",
      "epoch 13 - total loss: 45.4000\n",
      "epoch 14 - total loss: 49.6726\n",
      "epoch 15 - total loss: 40.2434\n",
      "epoch 16 - total loss: 41.9442\n",
      "epoch 17 - total loss: 42.3096\n",
      "epoch 18 - total loss: 43.0505\n",
      "epoch 19 - total loss: 44.1663\n",
      "epoch 20 - total loss: 43.9261\n",
      "epoch 21 - total loss: 42.1905\n",
      "epoch 22 - total loss: 40.8568\n",
      "epoch 23 - total loss: 40.6121\n",
      "epoch 24 - total loss: 39.0650\n",
      "epoch 25 - total loss: 41.7234\n",
      "epoch 26 - total loss: 41.4370\n",
      "epoch 27 - total loss: 36.7540\n",
      "epoch 28 - total loss: 37.7497\n",
      "epoch 29 - total loss: 34.4935\n",
      "epoch 30 - total loss: 40.1772\n",
      "epoch 31 - total loss: 40.1458\n",
      "epoch 32 - total loss: 40.9589\n",
      "epoch 33 - total loss: 38.1028\n",
      "epoch 34 - total loss: 37.6547\n",
      "epoch 35 - total loss: 34.8821\n",
      "epoch 36 - total loss: 32.6857\n",
      "epoch 37 - total loss: 32.0172\n",
      "epoch 38 - total loss: 30.9541\n",
      "epoch 39 - total loss: 31.0278\n",
      "epoch 40 - total loss: 29.9302\n",
      "Train error =  13.545000000000002\n",
      "Test error =  13.280000000000001\n"
     ]
    }
   ],
   "source": [
    "train_network(net, train_loader, criterion, optimizer, iters=40)\n",
    "print(\"Train error = \", 100 - evaluate_net(net, train_loader))\n",
    "print(\"Test error = \", 100 - evaluate_net(net, test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was just a brief intro to PyTorch. Great tutorials are available at [https://pytorch.org/tutorials](https://pytorch.org/tutorials)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
